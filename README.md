# Neural Machine Translation (English â†’ Vietnamese) with Transformer

Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c nghiÃªn cá»©u vÃ  triá»ƒn khai cÃ¡c há»‡ thá»‘ng dá»‹ch mÃ¡y cho cáº·p ngÃ´n ngá»¯ Anh-Viá»‡t, bao gá»“m viá»‡c xÃ¢y dá»±ng mÃ´ hÃ¬nh Transformer tá»« cÃ¡c thÃ nh pháº§n cÆ¡ báº£n vÃ  tinh chá»‰nh mÃ´ hÃ¬nh pre-trained cho lÄ©nh vá»±c chuyÃªn biá»‡t. ÄÃ¢y lÃ  ná»™i dung thuá»™c bÃ i táº­p lá»›n mÃ´n Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn nÄƒm 2025.



## ğŸ“Œ Tá»•ng quan dá»± Ã¡n

Dá»± Ã¡n triá»ƒn khai hai hÆ°á»›ng tiáº¿p cáº­n chÃ­nh:
1.  **Transformer Code from Scratch**: Tá»± xÃ¢y dá»±ng kiáº¿n trÃºc Transformer Seq2Seq vÃ  huáº¥n luyá»‡n trÃªn bá»™ dá»¯ liá»‡u **IWSLT2015 En-Vi**.
2.  **Fine-tuning MarianMT**: Sá»­ dá»¥ng mÃ´ hÃ¬nh `Helsinki-NLP/opus-mt-en-vi` vÃ  tinh chá»‰nh cho bÃ i toÃ¡n dá»‹ch thuáº­t chuyÃªn ngÃ nh y táº¿ trong khuÃ´n khá»• cuá»™c thi **VLSP Medical MT**.

## ğŸ—ï¸ Kiáº¿n trÃºc & TÃ­nh nÄƒng

### 1. Transformer tá»« Ä‘áº§u (Scratch)
Triá»ƒn khai Ä‘áº§y Ä‘á»§ cÃ¡c thÃ nh pháº§n cá»‘t lÃµi báº±ng PyTorch:
* **Multi-Head Attention**: CÆ¡ cháº¿ chÃº Ã½ Ä‘a Ä‘áº§u giÃºp mÃ´ hÃ¬nh hiá»ƒu ngá»¯ cáº£nh tá»‘t hÆ¡n.
* **Encoder/Decoder Blocks**: CÃ¡c khá»‘i mÃ£ hÃ³a vÃ  giáº£i mÃ£ tiÃªu chuáº©n vá»›i Residual Connection vÃ  Layer Normalization.
* **Positional Encoding**: NhÃºng thÃ´ng tin vá»‹ trÃ­ vÃ o chuá»—i Ä‘áº§u vÃ o do Transformer khÃ´ng cÃ³ tÃ­nh tuáº§n tá»± nhÆ° RNN.
* **Label Smoothing & Noam Scheduler**: Tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh há»™i tá»¥ cá»§a mÃ´ hÃ¬nh.
* **Beam Search Decoding**: Thuáº­t toÃ¡n giáº£i mÃ£ giÃºp tÃ¬m ra báº£n dá»‹ch cÃ³ xÃ¡c suáº¥t cao nháº¥t.
* **Tokenization**: Sá»­ dá»¥ng Byte Pair Encoding (BPE) Ä‘á»ƒ xá»­ lÃ½ tá»« vá»±ng hiá»‡u quáº£.

### 2. Fine-tuning cho Y táº¿ (VLSP Medical MT)
* Tinh chá»‰nh mÃ´ hÃ¬nh **MarianMT** trÃªn táº­p dá»¯ liá»‡u chuyÃªn ngÃ nh y khoa.
* Kháº£ nÄƒng dá»‹ch chÃ­nh xÃ¡c cÃ¡c thuáº­t ngá»¯ y há»c phá»©c táº¡p mÃ  cÃ¡c mÃ´ hÃ¬nh thÃ´ng thÆ°á»ng dá»… máº¯c lá»—i.

## ğŸ’¾ Model Checkpoints

Báº¡n cÃ³ thá»ƒ táº£i xuá»‘ng cÃ¡c trá»ng sá»‘ mÃ´ hÃ¬nh (weights) Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n sáºµn táº¡i liÃªn káº¿t dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ cháº¡y thá»­ nghiá»‡m ngay mÃ  khÃ´ng cáº§n huáº¥n luyá»‡n láº¡i:

ğŸ‘‰ **[Google Drive - Trained Models](https://drive.google.com/drive/folders/1gDUzKpvDsgoGJeulh3416IfbyYA_o9Qy?usp=drive_link)**

## ğŸ“Š Káº¿t quáº£ thá»±c nghiá»‡m

Káº¿t quáº£ Ä‘Æ°á»£c Ä‘o lÆ°á»ng báº±ng chá»‰ sá»‘ BLEU (Bilingual Evaluation Understudy):

| PhÆ°Æ¡ng phÃ¡p | Táº­p dá»¯ liá»‡u | Sá»‘ cÃ¢u Test | BLEU Score |
| :--- | :--- | :--- | :--- |
| **Transformer (Scratch)** | IWSLT2015 | 500 | **13.18** |
| **MarianMT (Fine-tune)** | VLSP Medical | 3000 | **47.49** |

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

* `transformer.ipynb`: Notebook chi tiáº¿t quÃ¡ trÃ¬nh xÃ¢y dá»±ng mÃ´ hÃ¬nh tá»« Ä‘áº§u, tá»« khÃ¢u xá»­ lÃ½ dá»¯ liá»‡u Ä‘áº¿n lÃºc inference.
* `NLP_task2.ipynb`: Notebook thá»±c hiá»‡n fine-tuning mÃ´ hÃ¬nh MarianMT trÃªn GPU (A100/T4).
* `NLP_report_v2.pdf`: BÃ¡o cÃ¡o ká»¹ thuáº­t chi tiáº¿t vá» lÃ½ thuyáº¿t vÃ  phÃ¢n tÃ­ch káº¿t quáº£.
